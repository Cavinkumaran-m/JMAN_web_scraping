import requests
import json
import pandas
from alive_progress import alive_bar


print("\nWeb Scraper for the Lenskart Site\n")

try:
    # Logic to read api endpoints from the file
    with open("api_endpoints.txt", "r") as APIs:

        products = []
        stores = []
        store_locations = ["Chennai","Delhi","Mumbai","Bangalore","Hyderabad","Ahmedabad","Kolkata","Surat","Pune","Jaipur"]

        def fetch_products(api):
            json_data = requests.get(api).json()
            products.extend(json_data["result"]["product_list"])

        def fetch_stores(api,bar):
            for location in store_locations:
                bar()
                bar.text = "->\tFetching: Stores at "+ location
                """
                This Xstoreaccesskey is user specific and generated by js during site rendering and saved in
                the browser. I obtained this key from inspecting my browser using dev-tools in chrome.
                By the time you run this code, this key might be expired. So make sure to replace it with 
                your own key. The key can be found in api calls like "list", "header" and so on.
                """
                res = requests.post(api, headers={'Xstoreaccesskey': 'pNRq8BGvIHk/G9AwlBxKG5lz97eYDaxnWO0YYs+VrMY='}, json={"keyword":location,"perPage":9999}).json()
                if res['status'] == 401:
                    print("Stores scraping unsuccessful (Xstoreaccesskey invalid)\n*Check source code for info*")
                    return
                stores.extend(res["data"]["data"])
            data = pandas.DataFrame(stores)
            data.to_csv("stores.csv", encoding="utf-8", index=False)

        # Logic for data parsing along with the progress bar
        with alive_bar(sum(1 for line in APIs) + len(store_locations), dual_line=True, bar="smooth") as bar:
            APIs.seek(0)
            while(True):
                bar()
                api = APIs.readline().replace("\n","")
                if len(api) == 0:
                    break
                elif api[0] == "#":
                    bar.text = "->\tFetching: "+api[1:]
                    if api[1:] == "Stores":
                        data = pandas.DataFrame(products)
                        data.to_csv("products.csv", encoding="utf-8", index=False)
                        api = APIs.readline().replace("\n","")
                        fetch_stores(api, bar)
                else:
                    fetch_products(api)

        print("\nShutting down Scraper\n")

except Exception as Ex:
    print("The following error has occurred:\n ", Ex)